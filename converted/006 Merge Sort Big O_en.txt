Now, let's look at the big O of merge sort.
Let's bring up a list here, and the first thing I'm going to talk about is space complexity.
So with merged sort, you start out with this original list, then you create two new lists called left
and right, and then you continue breaking these down.
So you start out with your original list and then you have eight new lists that each have a length of
one.
So the number of items being stored in memory have been doubled, so that means this is of in four space
complexity, the previous sorting algorithms that we've looked at are sorted in place.
That means we take the original list and we move things around inside of that list.
Merge sort is different than that in that it creates new lists.
So let's put this back up here and look at time complexity.
When we're breaking this in half, we do this in one, two, three steps, we had eight items.
It took us three steps.
This is going to be log in because two to the third power is eight.
It took us three steps to break this in half with eight items.
But let's look at what happens when we put these together like this.
So think back to our merge function, our helper function.
It had those while loops in there that went through each number one by one to be able to combine these
into a sorted list.
So breaking these apart is of log in, putting it back together because of having to loop through each
item with the merge function is a then.
And so that's where we get the O of in times log in time complexity for merge sort.
So let's look at this on the graph.
And when it comes to sorting algorithms, only the two on the left really matter.
I'm going to grill out the ones on the right.
The first three sorting algorithms that were created were a then squared bubble sort insertion sort
selection sort, but this one is much more efficient over than times.
Log in oh, of times.
Log in is the most efficient that you can make a sorting algorithm that's going to sort multiple types
of data.
There are certain efficiencies and sorting only numbers and there are some sorting algorithms that can
run more efficient than this.
But you can only sort numbers with them.
But if you're going to sort multiple types of data, this is as good as it gets.
So all of the end times log in is much more efficient than oh squared.
And it may not look that way on this graph, but the axis on the left, the Y axis only goes up to 75.
If the axis went to a thousand or it went to a million, you would see that there is a huge difference
between olivine squared and O of end times log in.
And that is our overview of merge sort.
Bego.
